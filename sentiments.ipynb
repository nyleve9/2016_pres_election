{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (12, 9) #<--- large default figures\n",
    "\n",
    "# Plot text elements\n",
    "rcParams['axes.labelsize'] = 17\n",
    "rcParams['axes.titlesize'] = 17\n",
    "rcParams['xtick.labelsize'] = 15\n",
    "rcParams['ytick.labelsize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/Workspaces/springboard/capstone/electiontweets\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/evelyn/Workspaces/springboard/capstone/electiontweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_files = ['#makeamericagreatagain_2016-11-10_to_2016-11-14.json',\n",
    "               '#makeamericagreatagain_2016-11-09.json',\n",
    "               '#makeamericagreatagain_2016-11-08.json',\n",
    "               '#makeamericagreatagain_2016-11-07.json',\n",
    "               '#makeamericagreatagain_2016-11-06.json',\n",
    "               '#makeamericagreatagain_2016-11-05.json',\n",
    "               '#makeamericagreatagain_2016-11-04.json',\n",
    "               '#makeamericagreatagain_2016-11-01.json',\n",
    "               '#makeamericagreatagain_2016-10-31.json']\n",
    "\n",
    "tweets = []\n",
    "for file in tweet_files:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158160"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Mon Nov 14 23:59:45 +0000 2016',\n",
       " 'entities': {'hashtags': [{'indices': [47, 69],\n",
       "    'text': 'MakeAmericaGreatAgain'}],\n",
       "  'media': [{'display_url': 'pic.twitter.com/QK4tkIOBHY',\n",
       "    'expanded_url': 'https://twitter.com/The_Trump_Train/status/798299732451950600/photo/1',\n",
       "    'id': 798299726424707076,\n",
       "    'id_str': '798299726424707076',\n",
       "    'indices': [70, 93],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "    'sizes': {'large': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "     'medium': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "     'small': {'h': 240, 'resize': 'fit', 'w': 680},\n",
       "     'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "    'source_status_id': 798299732451950600,\n",
       "    'source_status_id_str': '798299732451950600',\n",
       "    'source_user_id': 4102376488,\n",
       "    'source_user_id_str': '4102376488',\n",
       "    'type': 'photo',\n",
       "    'url': 'https://t.co/QK4tkIOBHY'}],\n",
       "  'symbols': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'id': 4102376488,\n",
       "    'id_str': '4102376488',\n",
       "    'indices': [3, 19],\n",
       "    'name': 'The Trump Train',\n",
       "    'screen_name': 'The_Trump_Train'}]},\n",
       " 'extended_entities': {'media': [{'display_url': 'pic.twitter.com/QK4tkIOBHY',\n",
       "    'expanded_url': 'https://twitter.com/The_Trump_Train/status/798299732451950600/photo/1',\n",
       "    'id': 798299726424707076,\n",
       "    'id_str': '798299726424707076',\n",
       "    'indices': [70, 93],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "    'sizes': {'large': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "     'medium': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "     'small': {'h': 240, 'resize': 'fit', 'w': 680},\n",
       "     'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "    'source_status_id': 798299732451950600,\n",
       "    'source_status_id_str': '798299732451950600',\n",
       "    'source_user_id': 4102376488,\n",
       "    'source_user_id_str': '4102376488',\n",
       "    'type': 'photo',\n",
       "    'url': 'https://t.co/QK4tkIOBHY'}]},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 798314509337235456,\n",
       " 'id_str': '798314509337235456',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'place': None,\n",
       " 'possibly_sensitive': False,\n",
       " 'retweet_count': 307,\n",
       " 'retweeted': False,\n",
       " 'retweeted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Mon Nov 14 23:01:02 +0000 2016',\n",
       "  'entities': {'hashtags': [{'indices': [26, 48],\n",
       "     'text': 'MakeAmericaGreatAgain'}],\n",
       "   'media': [{'display_url': 'pic.twitter.com/QK4tkIOBHY',\n",
       "     'expanded_url': 'https://twitter.com/The_Trump_Train/status/798299732451950600/photo/1',\n",
       "     'id': 798299726424707076,\n",
       "     'id_str': '798299726424707076',\n",
       "     'indices': [49, 72],\n",
       "     'media_url': 'http://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "     'sizes': {'large': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "      'medium': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "      'small': {'h': 240, 'resize': 'fit', 'w': 680},\n",
       "      'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "     'type': 'photo',\n",
       "     'url': 'https://t.co/QK4tkIOBHY'}],\n",
       "   'symbols': [],\n",
       "   'urls': [],\n",
       "   'user_mentions': []},\n",
       "  'extended_entities': {'media': [{'display_url': 'pic.twitter.com/QK4tkIOBHY',\n",
       "     'expanded_url': 'https://twitter.com/The_Trump_Train/status/798299732451950600/photo/1',\n",
       "     'id': 798299726424707076,\n",
       "     'id_str': '798299726424707076',\n",
       "     'indices': [49, 72],\n",
       "     'media_url': 'http://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/CxQhXyHWEAQdbmv.jpg',\n",
       "     'sizes': {'large': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "      'medium': {'h': 265, 'resize': 'fit', 'w': 750},\n",
       "      'small': {'h': 240, 'resize': 'fit', 'w': 680},\n",
       "      'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "     'type': 'photo',\n",
       "     'url': 'https://t.co/QK4tkIOBHY'}]},\n",
       "  'favorite_count': 829,\n",
       "  'favorited': False,\n",
       "  'geo': None,\n",
       "  'id': 798299732451950600,\n",
       "  'id_str': '798299732451950600',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'en',\n",
       "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 307,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  'text': 'The best picture of 2016! #MakeAmericaGreatAgain https://t.co/QK4tkIOBHY',\n",
       "  'truncated': False,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Tue Nov 03 05:07:18 +0000 2015',\n",
       "   'default_profile': True,\n",
       "   'default_profile_image': False,\n",
       "   'description': 'The official Twitter network for Donald Trump and The Trump Train movement! #MakeAmericaGreatAgain',\n",
       "   'entities': {'description': {'urls': []}},\n",
       "   'favourites_count': 6061,\n",
       "   'follow_request_sent': False,\n",
       "   'followers_count': 87877,\n",
       "   'following': False,\n",
       "   'friends_count': 89989,\n",
       "   'geo_enabled': False,\n",
       "   'has_extended_profile': False,\n",
       "   'id': 4102376488,\n",
       "   'id_str': '4102376488',\n",
       "   'is_translation_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'lang': 'en',\n",
       "   'listed_count': 281,\n",
       "   'location': 'The White House',\n",
       "   'name': 'The Trump Train',\n",
       "   'notifications': False,\n",
       "   'profile_background_color': 'C0DEED',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_tile': False,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4102376488/1452492091',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/686427697887731713/q0XMtMoW_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/686427697887731713/q0XMtMoW_normal.jpg',\n",
       "   'profile_link_color': '1DA1F2',\n",
       "   'profile_sidebar_border_color': 'C0DEED',\n",
       "   'profile_sidebar_fill_color': 'DDEEF6',\n",
       "   'profile_text_color': '333333',\n",
       "   'profile_use_background_image': True,\n",
       "   'protected': False,\n",
       "   'screen_name': 'The_Trump_Train',\n",
       "   'statuses_count': 2414,\n",
       "   'time_zone': None,\n",
       "   'translator_type': 'none',\n",
       "   'url': None,\n",
       "   'utc_offset': None,\n",
       "   'verified': False}},\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'text': 'RT @The_Trump_Train: The best picture of 2016! #MakeAmericaGreatAgain https://t.co/QK4tkIOBHY',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Wed Jan 27 14:16:43 +0000 2016',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'description': '',\n",
       "  'entities': {'description': {'urls': []}},\n",
       "  'favourites_count': 16079,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 459,\n",
       "  'following': False,\n",
       "  'friends_count': 94,\n",
       "  'geo_enabled': True,\n",
       "  'has_extended_profile': False,\n",
       "  'id': 4853583291,\n",
       "  'id_str': '4853583291',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 143,\n",
       "  'location': '',\n",
       "  'name': 'Suzanne Rivkin',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': None,\n",
       "  'profile_background_image_url_https': None,\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/774347307051614208/oZNIM1GC_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/774347307051614208/oZNIM1GC_normal.jpg',\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'rivkin_suzanne',\n",
       "  'statuses_count': 42980,\n",
       "  'time_zone': None,\n",
       "  'translator_type': 'none',\n",
       "  'url': None,\n",
       "  'utc_offset': None,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:45 +0000 2016</td>\n",
       "      <td>{'media': [{'type': 'photo', 'id_str': '798299...</td>\n",
       "      <td>{'media': [{'type': 'photo', 'id_str': '798299...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314509337235456</td>\n",
       "      <td>798314509337235456</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'The best picture of 2016! #MakeAmeri...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @The_Trump_Train: The best picture of 2016!...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:44 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'classy'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314503779786754</td>\n",
       "      <td>798314503779786754</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Will @RichardGrenell have a role in the Trump ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:38 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'Day1Cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314479985557504</td>\n",
       "      <td>798314479985557504</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7153</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'RT if you supported @realDonaldTrump...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>RT @KatrinaPierson: RT if you supported @realD...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:38 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'ObamaPr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314479339585536</td>\n",
       "      <td>798314479339585536</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'Sorry #ObamaPresser we're not doing ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @WillaimShat: Sorry #ObamaPresser we're not...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:32 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'stronge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314452101853184</td>\n",
       "      <td>798314452101853184</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>@KMWalsh_GOP UNITED States of America!!! #stro...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  \\\n",
       "0         None        None  Mon Nov 14 23:59:45 +0000 2016   \n",
       "1         None        None  Mon Nov 14 23:59:44 +0000 2016   \n",
       "2         None        None  Mon Nov 14 23:59:38 +0000 2016   \n",
       "3         None        None  Mon Nov 14 23:59:38 +0000 2016   \n",
       "4         None        None  Mon Nov 14 23:59:32 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'media': [{'type': 'photo', 'id_str': '798299...   \n",
       "1  {'symbols': [], 'hashtags': [{'text': 'classy'...   \n",
       "2  {'symbols': [], 'hashtags': [{'text': 'Day1Cre...   \n",
       "3  {'symbols': [], 'hashtags': [{'text': 'ObamaPr...   \n",
       "4  {'symbols': [], 'hashtags': [{'text': 'stronge...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'type': 'photo', 'id_str': '798299...               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "  favorited   geo                  id              id_str  \\\n",
       "0     False  None  798314509337235456  798314509337235456   \n",
       "1     False  None  798314503779786754  798314503779786754   \n",
       "2     False  None  798314479985557504  798314479985557504   \n",
       "3     False  None  798314479339585536  798314479339585536   \n",
       "4     False  None  798314452101853184  798314452101853184   \n",
       "\n",
       "                         ...                         quoted_status  \\\n",
       "0                        ...                                   NaN   \n",
       "1                        ...                                   NaN   \n",
       "2                        ...                                   NaN   \n",
       "3                        ...                                   NaN   \n",
       "4                        ...                                   NaN   \n",
       "\n",
       "   quoted_status_id quoted_status_id_str  retweet_count retweeted  \\\n",
       "0               NaN                  NaN            307     False   \n",
       "1               NaN                  NaN              0     False   \n",
       "2               NaN                  NaN           7153     False   \n",
       "3               NaN                  NaN              3     False   \n",
       "4               NaN                  NaN              0     False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'text': 'The best picture of 2016! #MakeAmeri...   \n",
       "1                                                NaN   \n",
       "2  {'text': 'RT if you supported @realDonaldTrump...   \n",
       "3  {'text': 'Sorry #ObamaPresser we're not doing ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/#!/download/ipad\" ...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  RT @The_Trump_Train: The best picture of 2016!...     False   \n",
       "1  Will @RichardGrenell have a role in the Trump ...     False   \n",
       "2  RT @KatrinaPierson: RT if you supported @realD...     False   \n",
       "3  RT @WillaimShat: Sorry #ObamaPresser we're not...     False   \n",
       "4  @KMWalsh_GOP UNITED States of America!!! #stro...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'is_translator': False, 'profile_use_backgrou...  \n",
       "1  {'is_translator': False, 'profile_use_backgrou...  \n",
       "2  {'is_translator': False, 'profile_use_backgrou...  \n",
       "3  {'is_translator': False, 'profile_use_backgrou...  \n",
       "4  {'is_translator': False, 'profile_use_backgrou...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf=pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetdf=tweetdf[tweetdf.lang=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:45 +0000 2016</td>\n",
       "      <td>{'media': [{'type': 'photo', 'id_str': '798299...</td>\n",
       "      <td>{'media': [{'type': 'photo', 'id_str': '798299...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314509337235456</td>\n",
       "      <td>798314509337235456</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'The best picture of 2016! #MakeAmeri...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @The_Trump_Train: The best picture of 2016!...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:44 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'classy'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314503779786754</td>\n",
       "      <td>798314503779786754</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Will @RichardGrenell have a role in the Trump ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:38 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'Day1Cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314479985557504</td>\n",
       "      <td>798314479985557504</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7153</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'RT if you supported @realDonaldTrump...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>RT @KatrinaPierson: RT if you supported @realD...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:38 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'ObamaPr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314479339585536</td>\n",
       "      <td>798314479339585536</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'text': 'Sorry #ObamaPresser we're not doing ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @WillaimShat: Sorry #ObamaPresser we're not...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Nov 14 23:59:32 +0000 2016</td>\n",
       "      <td>{'symbols': [], 'hashtags': [{'text': 'stronge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>798314452101853184</td>\n",
       "      <td>798314452101853184</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>@KMWalsh_GOP UNITED States of America!!! #stro...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'is_translator': False, 'profile_use_backgrou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  \\\n",
       "0         None        None  Mon Nov 14 23:59:45 +0000 2016   \n",
       "1         None        None  Mon Nov 14 23:59:44 +0000 2016   \n",
       "2         None        None  Mon Nov 14 23:59:38 +0000 2016   \n",
       "3         None        None  Mon Nov 14 23:59:38 +0000 2016   \n",
       "4         None        None  Mon Nov 14 23:59:32 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'media': [{'type': 'photo', 'id_str': '798299...   \n",
       "1  {'symbols': [], 'hashtags': [{'text': 'classy'...   \n",
       "2  {'symbols': [], 'hashtags': [{'text': 'Day1Cre...   \n",
       "3  {'symbols': [], 'hashtags': [{'text': 'ObamaPr...   \n",
       "4  {'symbols': [], 'hashtags': [{'text': 'stronge...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'type': 'photo', 'id_str': '798299...               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "  favorited   geo                  id              id_str  \\\n",
       "0     False  None  798314509337235456  798314509337235456   \n",
       "1     False  None  798314503779786754  798314503779786754   \n",
       "2     False  None  798314479985557504  798314479985557504   \n",
       "3     False  None  798314479339585536  798314479339585536   \n",
       "4     False  None  798314452101853184  798314452101853184   \n",
       "\n",
       "                         ...                         quoted_status  \\\n",
       "0                        ...                                   NaN   \n",
       "1                        ...                                   NaN   \n",
       "2                        ...                                   NaN   \n",
       "3                        ...                                   NaN   \n",
       "4                        ...                                   NaN   \n",
       "\n",
       "   quoted_status_id quoted_status_id_str  retweet_count retweeted  \\\n",
       "0               NaN                  NaN            307     False   \n",
       "1               NaN                  NaN              0     False   \n",
       "2               NaN                  NaN           7153     False   \n",
       "3               NaN                  NaN              3     False   \n",
       "4               NaN                  NaN              0     False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'text': 'The best picture of 2016! #MakeAmeri...   \n",
       "1                                                NaN   \n",
       "2  {'text': 'RT if you supported @realDonaldTrump...   \n",
       "3  {'text': 'Sorry #ObamaPresser we're not doing ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/#!/download/ipad\" ...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  RT @The_Trump_Train: The best picture of 2016!...     False   \n",
       "1  Will @RichardGrenell have a role in the Trump ...     False   \n",
       "2  RT @KatrinaPierson: RT if you supported @realD...     False   \n",
       "3  RT @WillaimShat: Sorry #ObamaPresser we're not...     False   \n",
       "4  @KMWalsh_GOP UNITED States of America!!! #stro...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'is_translator': False, 'profile_use_backgrou...  \n",
       "1  {'is_translator': False, 'profile_use_backgrou...  \n",
       "2  {'is_translator': False, 'profile_use_backgrou...  \n",
       "3  {'is_translator': False, 'profile_use_backgrou...  \n",
       "4  {'is_translator': False, 'profile_use_backgrou...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135092"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweetdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158155</th>\n",
       "      <td>793045213505789952</td>\n",
       "      <td>RT @WeNeedTrump: Post game coverage of the Cub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158156</th>\n",
       "      <td>793045207369576448</td>\n",
       "      <td>RT @EricaMelone: @donnabrazile Please golden, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158157</th>\n",
       "      <td>793045188700676096</td>\n",
       "      <td>RT @TeresaEdelglass: \"I'm going to deliver the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158158</th>\n",
       "      <td>793045160544337920</td>\n",
       "      <td>RT @WeNeedTrump: Please RETWEET! This video co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158159</th>\n",
       "      <td>793045113542840321</td>\n",
       "      <td>Eric Holder's Endorsement Is the KISS OF DEATH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweetid                                              tweet\n",
       "158155  793045213505789952  RT @WeNeedTrump: Post game coverage of the Cub...\n",
       "158156  793045207369576448  RT @EricaMelone: @donnabrazile Please golden, ...\n",
       "158157  793045188700676096  RT @TeresaEdelglass: \"I'm going to deliver the...\n",
       "158158  793045160544337920  RT @WeNeedTrump: Please RETWEET! This video co...\n",
       "158159  793045113542840321  Eric Holder's Endorsement Is the KISS OF DEATH..."
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringdf = pd.DataFrame()\n",
    "stringdf['tweetid'] = tweetdf['id']\n",
    "stringdf['tweet'] = tweetdf['text']\n",
    "stringdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135092"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stringdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135092"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringdf.tweetid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import regex\n",
    "import re\n",
    "\n",
    "#start process_tweet\n",
    "def processTweet(tweet):\n",
    "    # process the tweets\n",
    "\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stringdf.tweet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This processes text, but the indices are all \"0\"\n",
    "\n",
    "processdf = pd.DataFrame(columns=['processed'])\n",
    "for row in stringdf.text[:5]:\n",
    "    df=pd.DataFrame([[processTweet(row)]], columns=['processed'])\n",
    "    processdf = processdf.append(df)\n",
    "\n",
    "processdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a much better way, much faster\n",
    "\n",
    "processed = pd.DataFrame(stringdf.tweet.apply(lambda row: processTweet(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158155</th>\n",
       "      <td>rt AT_USER post game coverage of the cubs game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158156</th>\n",
       "      <td>rt AT_USER AT_USER please golden, sweet jesus....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158157</th>\n",
       "      <td>rt AT_USER \"i'm going to deliver the honest go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158158</th>\n",
       "      <td>rt AT_USER please retweet! this video could wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158159</th>\n",
       "      <td>eric holder's endorsement is the kiss of death...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet\n",
       "158155  rt AT_USER post game coverage of the cubs game...\n",
       "158156  rt AT_USER AT_USER please golden, sweet jesus....\n",
       "158157  rt AT_USER \"i'm going to deliver the honest go...\n",
       "158158  rt AT_USER please retweet! this video could wi...\n",
       "158159  eric holder's endorsement is the kiss of death..."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135092"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158155</th>\n",
       "      <td>rt AT_USER post game coverage of the cubs game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158156</th>\n",
       "      <td>rt AT_USER AT_USER please golden, sweet jesus....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158157</th>\n",
       "      <td>rt AT_USER \"i'm going to deliver the honest go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158158</th>\n",
       "      <td>rt AT_USER please retweet! this video could wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158159</th>\n",
       "      <td>eric holder's endorsement is the kiss of death...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "158155  rt AT_USER post game coverage of the cubs game...\n",
       "158156  rt AT_USER AT_USER please golden, sweet jesus....\n",
       "158157  rt AT_USER \"i'm going to deliver the honest go...\n",
       "158158  rt AT_USER please retweet! this video could wi...\n",
       "158159  eric holder's endorsement is the kiss of death..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.columns=['text']\n",
    "processed.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158150</th>\n",
       "      <td>793045291200937984</td>\n",
       "      <td>RT @WesRichardsonNY: Trump's tax cuts are exac...</td>\n",
       "      <td>rt AT_USER trump's tax cuts are exactly what a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158151</th>\n",
       "      <td>793045277234044929</td>\n",
       "      <td>RT @WeNeedTrump: Please RETWEET! This video co...</td>\n",
       "      <td>rt AT_USER please retweet! this video could wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158152</th>\n",
       "      <td>793045256698601472</td>\n",
       "      <td>RT @EricTrump: Always love being with you @Jud...</td>\n",
       "      <td>rt AT_USER always love being with you AT_USER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158153</th>\n",
       "      <td>793045249153200128</td>\n",
       "      <td>RT @EricTrump: On behalf of the entire family,...</td>\n",
       "      <td>rt AT_USER on behalf of the entire family, we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158154</th>\n",
       "      <td>793045237585285122</td>\n",
       "      <td>RT @DonaldJTrumpJr: Too funny to not share. Fr...</td>\n",
       "      <td>rt AT_USER too funny to not share. from AT_USE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158155</th>\n",
       "      <td>793045213505789952</td>\n",
       "      <td>RT @WeNeedTrump: Post game coverage of the Cub...</td>\n",
       "      <td>rt AT_USER post game coverage of the cubs game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158156</th>\n",
       "      <td>793045207369576448</td>\n",
       "      <td>RT @EricaMelone: @donnabrazile Please golden, ...</td>\n",
       "      <td>rt AT_USER AT_USER please golden, sweet jesus....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158157</th>\n",
       "      <td>793045188700676096</td>\n",
       "      <td>RT @TeresaEdelglass: \"I'm going to deliver the...</td>\n",
       "      <td>rt AT_USER \"i'm going to deliver the honest go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158158</th>\n",
       "      <td>793045160544337920</td>\n",
       "      <td>RT @WeNeedTrump: Please RETWEET! This video co...</td>\n",
       "      <td>rt AT_USER please retweet! this video could wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158159</th>\n",
       "      <td>793045113542840321</td>\n",
       "      <td>Eric Holder's Endorsement Is the KISS OF DEATH...</td>\n",
       "      <td>eric holder's endorsement is the kiss of death...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweetid                                              tweet  \\\n",
       "158150  793045291200937984  RT @WesRichardsonNY: Trump's tax cuts are exac...   \n",
       "158151  793045277234044929  RT @WeNeedTrump: Please RETWEET! This video co...   \n",
       "158152  793045256698601472  RT @EricTrump: Always love being with you @Jud...   \n",
       "158153  793045249153200128  RT @EricTrump: On behalf of the entire family,...   \n",
       "158154  793045237585285122  RT @DonaldJTrumpJr: Too funny to not share. Fr...   \n",
       "158155  793045213505789952  RT @WeNeedTrump: Post game coverage of the Cub...   \n",
       "158156  793045207369576448  RT @EricaMelone: @donnabrazile Please golden, ...   \n",
       "158157  793045188700676096  RT @TeresaEdelglass: \"I'm going to deliver the...   \n",
       "158158  793045160544337920  RT @WeNeedTrump: Please RETWEET! This video co...   \n",
       "158159  793045113542840321  Eric Holder's Endorsement Is the KISS OF DEATH...   \n",
       "\n",
       "                                                     text  \n",
       "158150  rt AT_USER trump's tax cuts are exactly what a...  \n",
       "158151  rt AT_USER please retweet! this video could wi...  \n",
       "158152  rt AT_USER always love being with you AT_USER ...  \n",
       "158153  rt AT_USER on behalf of the entire family, we ...  \n",
       "158154  rt AT_USER too funny to not share. from AT_USE...  \n",
       "158155  rt AT_USER post game coverage of the cubs game...  \n",
       "158156  rt AT_USER AT_USER please golden, sweet jesus....  \n",
       "158157  rt AT_USER \"i'm going to deliver the honest go...  \n",
       "158158  rt AT_USER please retweet! this video could wi...  \n",
       "158159  eric holder's endorsement is the kiss of death...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processdf=stringdf.join(processed)\n",
    "processdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_index() missing 1 required positional argument: 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-5e71a65ffb5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: set_index() missing 1 required positional argument: 'keys'"
     ]
    }
   ],
   "source": [
    "processdf.set_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135092"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taken from https://www.ravikiranj.net/posts/2012/code/how-build-twitter-sentiment-analyzer/\n",
    "\n",
    "* Lower Case - Convert the tweets to lower case.\n",
    "* URLs - I don't intend to follow the short urls and determine the content of the site, so we can eliminate all of these URLs via regular expression matching or replace with generic word URL.\n",
    "* @username - we can eliminate \"@username\" via regex matching or replace it with generic word AT_USER.\n",
    "* #hashtag - hash tags can give us some useful information, so it is useful to replace them with the exact same word without the hash. E.g. #nike replaced with 'nike'.\n",
    "* Punctuations and additional white spaces - remove punctuation at the start and ending of the tweets. E.g: ' the day is beautiful! ' replaced with 'the day is beautiful'. It is also helpful to replace multiple whitespaces with a single whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.twitter import Query, Streamer, Twitter, TweetViewer, TweetWriter, credsfromfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "twitter_samples.fileids()\n",
    "#nltk.download(twitter_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_samples.unicode_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is taken from:\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import pandas as pd       \n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a peek\n",
    "print train[\"review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(train[\"review\"][0])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print train[\"review\"][0]\n",
    "print example1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode for general steps in creating bag of words\n",
    "\n",
    "* list_BOW = []\n",
    "\n",
    "* For each review in the training set: Strip the newline character “n” at the end of each review.\n",
    "\n",
    "* Place a space before and after each of the following characters: .,()[]:;”  \n",
    "\n",
    "(This prevents sentences like “I like this book.It is engaging” being interpreted as \n",
    "[“I”, “like”, “this”, “book.It”, “is”, “engaging”].)\n",
    "\n",
    "* Tokenize the text by splitting it on spaces.\n",
    "\n",
    "* Remove tokens which consist of only a space, empty string or punctuation marks.\n",
    "\n",
    "* Append the tokens to list_BOW.\n",
    "list_BOW now contains all words occuring in the training set.\n",
    "\n",
    "* Place list_BOW in a Python Counter element. This counter now contains all occuring words together with their frequencies. Its entries can be sorted with the most_common() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation and numbers\n",
    "\n",
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print letters_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenization: convert into all lowercase and split into individual words\n",
    "\n",
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()               # Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()  # Download text data sets, including stop words\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to clean data\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_review = review_to_words( train[\"review\"][0] )\n",
    "print clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_reviews = train[\"review\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print status update every 1000 items that it processes (add this into code above)\n",
    "print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
    "clean_train_reviews = []\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
